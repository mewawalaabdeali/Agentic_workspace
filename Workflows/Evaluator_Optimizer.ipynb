{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0619ed45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Certainly! The Evaluator Optimizer with LangGraph refers to a conceptual framework or a toolchain typically found in advanced programming frameworks or language processing environments. They each have distinct roles:\\n\\n1. **Evaluator**: This is an engine that executes or interprets code or queries. In many language processing systems, an evaluator might execute scripts or commands, processing them into actions or computation results. The evaluator is often the core part of a runtime environment that translates high-level instructions into operations comprehensible by the underlying hardware or execution context.\\n\\n2. **Optimizer**: This component is crucial for enhancing the performance of code execution. An optimizer transforms an initial version of code into a more efficient form, attempting to reduce resource usage, execution time, or other costs. In programming languages, specifically compiled ones, optimization can include inlining functions, loop unrolling, or dead code elimination.\\n\\n3. **LangGraph**: This typically refers to a system or library that leverages graph structures to represent or process language constructs. Graph-based representations are beneficial in understanding the interrelations between different parts of a program or query, enabling sophisticated optimizations or transformations.\\n\\n### Syntax Overview\\n\\nUnfortunately, without specific documentation relating to a particular implementation of \"Evaluator Optimizer with LangGraph,\" the syntax can only be speculated on based on standard practices:\\n\\n- **Evaluator Syntax**: Usually involves the execution of coded language queries or scripts which would need to be syntactically compatible with whatever language the evaluator is designed to process.\\n  \\n  ```lang\\n  evaluate(script OrQuery)\\n  ```\\n\\n- **Optimizer Syntax**: Interfaces here are likely designed to indicate what level or type of optimization should be applied. They might have flags or configuration settings to direct the optimizerâ€™s behavior.\\n\\n  ```pseudo\\n  optimize(codeString, level=\"highPerformance\")\\n  ```\\n\\n- **LangGraph Syntax**: Building or querying graphs to assist with optimizations or transformations might involve specifying nodes and edges or traversing them.\\n\\n  ```pseudo\\n  graph.addNode(node)\\n  graph.addEdge(node1, node2)\\n  executeQueryOnGraph(graphQuery)\\n  ```\\n\\nTo effectively understand or use these components, one would typically need access to specific documentation from the developer or organization providing this functionality. Each system can have its own API and syntax depending on the programming language and intended use-cases.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 471, 'prompt_tokens': 20, 'total_tokens': 491, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-BsW1pJnwLNqgePkLTIV1GJK1bnJrE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--050fba50-b8e4-43e6-a901-07ba1605bd97-0', usage_metadata={'input_tokens': 20, 'output_tokens': 471, 'total_tokens': 491, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatOpenAI(model='gpt-4o')\n",
    "result = model.invoke(\"Tell me something about Evaluator Optimizer with Langgraph with syntax\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8820f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "import operator\n",
    "from typing_extensions import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from typing_extensions import TypedDict\n",
    "class State(TypedDict):\n",
    "    joke:str\n",
    "    topic:str\n",
    "    feedback:str\n",
    "    funny_or_not: str\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
