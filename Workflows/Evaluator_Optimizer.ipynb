{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0619ed45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\"Evaluator Optimizer\" and \"Langgraph\" do not appear to be widely recognized or established concepts, products, or frameworks in the public domain as of my last update in October 2023. It\\'s possible that they are newly introduced tools, proprietary technologies, or hypothetical terms in development or niche use.\\n\\nIf you\\'re referring to a specific technology stack or a new feature in a development tool, I recommend checking the official documentation or resources associated with the respective technology or framework. Typically, these resources provide the most accurate and up-to-date syntax examples and use cases.\\n\\nIf you can provide more context or specify whether these terms are related to a particular programming language, software tool, or domain (like machine learning, data processing, or natural language processing), I might be able to offer more targeted assistance or suggestions.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 161, 'prompt_tokens': 20, 'total_tokens': 181, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': None, 'id': 'chatcmpl-BsW9efY8kPPn3c0c2ekq9niC6L9lw', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--fd591eac-d88d-44f0-a399-70a35897dc14-0', usage_metadata={'input_tokens': 20, 'output_tokens': 161, 'total_tokens': 181, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatOpenAI(model='gpt-4o')\n",
    "result = model.invoke(\"Tell me something about Evaluator Optimizer with Langgraph with syntax\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8820f196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "import operator\n",
    "from typing_extensions import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    joke:str\n",
    "    topic:str\n",
    "    feedback:str\n",
    "    funny_or_not: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9db39a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedback(BaseModel):\n",
    "    grade: Literal[\"funny\", \"not funny\"] = Field(\n",
    "        description=\"Decide if the joke is funny or not\",\n",
    "    )\n",
    "    feedback: str = Field(\n",
    "        description=\"If the joke is not funny, provide the feedback on how to improve it.\"\n",
    "    )\n",
    "\n",
    "evaluator = model.with_structured_output(Feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f7c405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call_generator(state:State):\n",
    "    \"\"\"LLM generates a joke\"\"\"\n",
    "    if state.get(\"feedback\"):\n",
    "        msg = model.invoke(\n",
    "            f\"Write a joke about {state['topic']} but take into account the feedback: {state['feedback']}\"\n",
    "        )\n",
    "    else:\n",
    "        msg = model.invoke(\n",
    "            f\"Write a joke about {state['topic']}\"\n",
    "        )\n",
    "    return {\"joke\": msg.content}\n",
    "\n",
    "def llm_call_evaluator(state:State):\n",
    "    \"\"\"LLM evaluates the joke\"\"\"\n",
    "\n",
    "    grade = evaluator.invoke(f\"Grade teh joke {state['joke']}\")\n",
    "    return {\"funny_or_not\": grade.grade, \"feedback\":grade.feedback}\n",
    "\n",
    "def route_joke(state:State):\n",
    "    \"\"\"Route back to joke generator or end based on feedback from the evaluator\"\"\"\n",
    "\n",
    "    if state[\"funny_or_not\"] == \"funny\":\n",
    "        return \"Accepted\"\n",
    "    elif state[\"funny_or_not\"] == \"not_funny\":\n",
    "        return \"Rejected + Feedback\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1aec0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "#Add nodes\n",
    "workflow.add_node(\"llm_call_generator\", llm_call_generator)\n",
    "workflow.add_node(\"llm_call_evaluator\", llm_call_evaluator)\n",
    "\n",
    "#Add edges\n",
    "workflow.add_edge(START, \"llm_call_generator\")\n",
    "workflow.add_edge(\"llm_call_generator\", \"llm_call_evaluator\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"llm_call_evaluator\",\n",
    "    route_joke,\n",
    "    { #Name returned by route_joke: Namme of next node to visit\n",
    "        \"Accepted\":END,\n",
    "        \"Rejected + Feedback\":\"llm_call_generator\",\n",
    "\n",
    "    }\n",
    ")\n",
    "\n",
    "optimized_workflow = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecd5e232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the agentic AI system apply for a job at the bakery?\n",
      "\n",
      "Because it heard they kneaded a rise in self-awareness!\n"
     ]
    }
   ],
   "source": [
    "state = optimized_workflow.invoke({\"topic\":\"Agentic AI SYstems\"})\n",
    "print(state[\"joke\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
