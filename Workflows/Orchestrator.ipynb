{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3aef0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a288987b44', 'id': 'chatcmpl-BrpM4XmmWEz5U3ZXLsjPk0AMYgnCy', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--23a78a4a-412c-4bda-84fe-065e0bde9608-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatOpenAI(model='gpt-4o')\n",
    "result = model.invoke(\"hello\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7392cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "import operator\n",
    "from typing_extensions import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29da1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Section(BaseModel):\n",
    "    name:str=Field(description=\"Name for this section of the report\")\n",
    "    description:str=Field(description=\"Brief overview of the main topics and concepts of the section\")\n",
    "\n",
    "class Sections(BaseModel):\n",
    "    sections:List[Section]=Field(\n",
    "        description=\"Sections of the report\"\n",
    "    )\n",
    "\n",
    "planner = model.with_structured_output(Sections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ace2c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Creating Workers Dynamically in LangGraph\n",
    "from langgraph.constants import Send\n",
    "\n",
    "class State(TypedDict):\n",
    "    topic:str #Report Topic\n",
    "    sections: list[Section] #List of report sections\n",
    "    completed_sections: Annotated[list, operator.add] #All workers write to this key in parallel\n",
    "    final_report:str #Final report\n",
    "\n",
    "class WorkerState(TypedDict):\n",
    "    section:Section\n",
    "    completed_sections:Annotated[list, operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18473a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orchestrator(state:State):\n",
    "    \"\"\"Orchestrator that generates a plan for the report\"\"\"\n",
    "    #Generate Queries\n",
    "    report_sections = planner.invoke(\n",
    "        [\n",
    "            SystemMessage(content=\"Generate a plan for the report\"),\n",
    "            HumanMessage(content=f\"Here is the report topic: {state['topic']}\"),\n",
    "        ]\n",
    "    )\n",
    "    print(\"Report Sections: \", report_sections)\n",
    "    return {\"sections\": report_sections.sections}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77eeced0",
   "metadata": {},
   "source": [
    "### LLM Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "561c7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call(state: WorkerState):\n",
    "    \"\"\"Worker writes a section of the report\"\"\"\n",
    "    section = model.invoke(\n",
    "        [\n",
    "        SystemMessage(\n",
    "            content = f\"Write a report section following the provided name and description. Inclue no preamble for each section. Use markdown formatting\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=f\"Here is the section name: {state['section'].name} and description: {state['section'].description}\"\n",
    "        ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\"completed sections\": [section.content]}\n",
    "\n",
    "def assign_workers(state:State):\n",
    "    \"\"\"Assign a worker to each section in the plan\"\"\"\n",
    "    #Kick off section writing in parallel via Send() API\n",
    "    return [Send(\"llm_call\", {\"section\":s}) for s in state[\"sections\"]]\n",
    "\n",
    "def synthesizer(state: State):\n",
    "    \"\"\"Synthesize full report from sections\"\"\"\n",
    "    #List of completed sections\n",
    "    completed_sections = state[\"completed_sections\"]\n",
    "\n",
    "    #Format completed section to str to use as context for final sections\n",
    "    completed_report_sections = \"\\n\\n---\\n\\n\".join(completed_sections)\n",
    "    return {\"final_report\": completed_report_sections}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c78d9e6",
   "metadata": {},
   "source": [
    "### Build Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa073bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "orchestrator_worker_builder = StateGraph(State)\n",
    "\n",
    "#Add the nodes\n",
    "orchestrator_worker_builder.add_node(\"orchestrator\", orchestrator)\n",
    "orchestrator_worker_builder.add_node(\"llm_call\", llm_call)\n",
    "orchestrator_worker_builder.add_node(\"synthesizer\", synthesizer)\n",
    "\n",
    "#Add edges to connect nodes\n",
    "orchestrator_worker_builder.add_edge(START, \"orchestrator\")\n",
    "orchestrator_worker_builder.add_conditional_edges(\n",
    "    \"orchestrator\", assign_workers, [\"llm_call\"]\n",
    ")\n",
    "orchestrator_worker_builder.add_edge(\"llm_call\", \"synthesizer\")\n",
    "orchestrator_worker_builder.add_edge(\"synthesizer\", END)\n",
    "\n",
    "orchestrator_worker = orchestrator_worker_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "510e068a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Sections:  sections=[Section(name='Introduction', description='This section will introduce the concept of Agentic AI RAGs (Retrieval-Augmented Generation systems), outlining their historical context, emergence, and relevance in contemporary AI developments. It will also briefly touch on the objective of the report to explore the potential applications and implications of these systems.'), Section(name='Understanding Agentic AI RAGs', description='This section will delve deeper into what Agentic AI RAGs are, providing a clear definition and explanation. It will cover the principles behind retrieval-augmented generation and how it integrates with agency â€“ the ability of AI to perform autonomous tasks. Examples of current implementations and theoretical frameworks will be discussed.'), Section(name='Technical Architecture of Agentic AI RAGs', description='An exploration of the technical underpinnings of Agentic AI RAGs, detailing the architecture, components, and technologies involved. This section will cover both the retrieval mechanisms and the generation models that these systems utilize, including advancements in neural networks and data retrieval algorithms.'), Section(name='Applications and Use Cases', description='This section will explore the practical applications of Agentic AI RAGs across various industries, such as healthcare, finance, customer service, and education. Case studies will be included to highlight specific use cases and the benefits realized through their deployment.'), Section(name='Ethical and Social Implications', description='An analysis of the ethical considerations and societal impacts posed by Agentic AI RAGs. This section will cover topics such as bias, transparency, accountability, privacy concerns, and the broader implications of AI systems capable of autonomous decision-making.'), Section(name='Challenges and Limitations', description='This section will identify and discuss the technical and operational challenges associated with developing and implementing Agentic AI RAGs. It will also cover the limitations of these systems in terms of scalability, data dependency, and potential areas for improvement.'), Section(name='Future Prospects of Agentic AI RAGs', description='An exploration into the future directions and technological advancements anticipated in the field of Agentic AI RAGs. This section will also discuss potential trends, innovations on the horizon, and strategic considerations for organizations considering these systems.'), Section(name='Conclusion and Recommendations', description='The report will conclude with a summary of key findings and the significance of Agentic AI RAGs. It will also provide recommendations for researchers, developers, and businesses on leveraging these technologies responsibly and effectively.')]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = orchestrator_worker.invoke({\"topic\":\"Create a report on Agentic AI RAGs\"})\n",
    "from IPython.display import Markdown\n",
    "Markdown(state[\"final_report\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
